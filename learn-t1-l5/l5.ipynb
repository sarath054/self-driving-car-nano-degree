{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction To Neural Networks\n",
    "Learn linear regression, perceptron, gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-9 AND Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Find the weights and bias for AND perceptron\n",
    "1. Plotting the points on a graph shows that [(0,0), (0,1), (1,0), (1,1)] form a square\n",
    "2. Getting the equation of the diagonal not passing through the origin -> x + y = 1\n",
    "3. The points on the line [(0,1), (1,0)] are `False` outputs for the perceptron\n",
    "4. So the required line will be a parallel line to x + y = 1 away from the origin.\n",
    "5. We can take any value for bias like -1.1, -2, -1.0001\n",
    "6. If we go beyond -2, our line will cross (1, 1) point which is a `Truth` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set weight and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# take inputs (ideally for real cases, these would be read from some source later)\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "# we already know what will be the outputs for above (AND logic table)\n",
    "correct_outputs = [False, False, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1*test_input[0] + weight2*test_input[1] + bias\n",
    "    output = int (linear_combination >= 0)\n",
    "    is_correct_output = 'Yes' if output == correct_output else 'No'\n",
    "    output_str = 'True' if output == 1 else 'False'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, output_str, correct_output, is_correct_output])\n",
    "\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Print the output\n",
    "num_wrong = len([output[6] for output in outputs if output[6] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns= ['Input 1', 'Input 2', 'Linear Combination', 'Activation Output', 'Output Label', 'Expected Output', 'Is correct'])\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check how many are correct and proceed\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-10 OR and NOT perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Find the weights and bias for OR perceptron\n",
    "1. Plotting the points on a graph shows that [(0,0), (0,1), (1,0), (1,1)] form a square\n",
    "2. Getting the equation of the diagonal not passing through the origin -> x + y = 1\n",
    "3. The points on the line [(0,1), (1,0)] are `True` outputs for the perceptron\n",
    "4. So the required line will be x + y = 1 or a parallel line towards the origin.\n",
    "5. We can take any value for bias like -1.0, -0.9, -0.0001\n",
    "6. If we go beyond 0, our line will cross (0, 0) point which is a `False` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# set weights and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -0.00001\n",
    "\n",
    "# take inputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "\n",
    "outputs = []\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1*test_input[0] + weight2*test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    output_str = 'True' if output == 1 else 'False'\n",
    "    is_correct_output = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, output_str, correct_output, is_correct_output])\n",
    "\n",
    "num_wrong = len([output[6] for output in outputs if output[6] == 'No'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', 'Input 2', 'Linear Combination', 'Activation Output', 'Output Label', 'Expected Output', 'Is Correct'])\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Find the weights and bias for NOT perceptron\n",
    "1. NOT only cares about one input and ignores the rest.\n",
    "2. Plotting the points on a graph shows that [(0,x), (1,x)] form a regions\n",
    "3. The dividing line between them -> x = 0.5\n",
    "4. The points to the right line [(1, x)] are `False` outputs for the perceptron\n",
    "5. So the required line will be x = 0.5 or a parallel line x = k where 0 < k < 1.\n",
    "6. We can take any value for bias like 1.0, 0.9, 0.0001 and slightly more negative weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# set the weights and bias\n",
    "weight1 = -1.00001\n",
    "weight2 = 0.0\n",
    "bias = 1.0\n",
    "\n",
    "# Take the inputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, True, False, False]\n",
    "\n",
    "outputs = []\n",
    "for test_input,correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1*test_input[0] + weight2*test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    output_str = 'True' if output == 1 else 'False'\n",
    "    # print(output, ':', correct_output, ':', output == correct_output)\n",
    "    is_correct_output = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, output_str, correct_output, is_correct_output])\n",
    "\n",
    "num_wrong = len([output[6] for output in outputs if output[6] == 'No'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "    \n",
    "output_frame = pd.DataFrame(outputs, columns = ['Input 1', 'Input 2', 'Linear Combination', 'Activation Output', 'Output Label', 'Expected Output', 'Is Correct'])\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-11 XOR perceptron\n",
    "1. XOR perceptron is not linearly separable. So we need to chain multiple perceptrons\n",
    "\n",
    "#### Helper Methods\n",
    "Converting the above Logic Gates into helper methods to solve the XOR perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def step_perceptron(test_input = [0.0, 0.0], weights = [0.0, 0.0], bias = 0.0):\n",
    "    linear_combination = weights[0]*test_input[0] + weights[1]*test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    return output == 1\n",
    "    \n",
    "def and_perceptron(test_input = [0.0, 0.0]):\n",
    "    return step_perceptron(test_input, weights = [1.0, 1.0], bias = -1.001)\n",
    "\n",
    "def or_perceptron(test_input = [0.0, 0.0]):\n",
    "    return step_perceptron(test_input, weights = [1.0, 1.0], bias = -0.001)\n",
    "\n",
    "def not_perceptron(test_input = [0.0, 0.0]):\n",
    "    return step_perceptron(test_input, weights = [-1.001, 0.0], bias = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# take inputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, False]\n",
    "\n",
    "outputs = []\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    inp_1 = int(and_perceptron([test_input[0], int(not_perceptron([test_input[1], 0]))]))\n",
    "    inp_2 = int(and_perceptron([test_input[1], int(not_perceptron([test_input[0], 0]))]))\n",
    "    # print(test_input[0], test_input[1], inp_1, inp_2, correct_output)\n",
    "    output = or_perceptron([inp_1, inp_2])\n",
    "    output_str = 'True' if output == 1 else 'False'\n",
    "    is_correct_output = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], output, output_str, correct_output, is_correct_output])\n",
    "    \n",
    "num_wrong = len([output[5] for output in outputs if output[5] == 'No'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "    \n",
    "output_frame = pd.DataFrame(outputs, columns = ['Input 1', 'Input 2', 'Activation Output', 'Output Label', 'Expected Output', 'Is Correct'])\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-12 Sigmoid Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "inputs = np.array([0.7, -0.3])\n",
    "weights = np.array([0.1, 0.8])\n",
    "bias = -0.1\n",
    "\n",
    "# linear_combination = weights[0]*inputs[0] + weights[1]*inputs[1] + bias\n",
    "linear_combination = np.dot(inputs, weights) + bias\n",
    "output = sigmoid(linear_combination)\n",
    "\n",
    "print('Output: ')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-15 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# define the derivative of sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# Input data\n",
    "x = np.array([0.1, 0.3])\n",
    "\n",
    "# Target\n",
    "y = 0.2\n",
    "\n",
    "# Input weights\n",
    "w = np.array([-0.8, 0.5])\n",
    "\n",
    "# Learning rate\n",
    "learn_rate = 0.5\n",
    "\n",
    "# NN output i.e., prediction\n",
    "nn_output = sigmoid(np.dot(x, w))\n",
    "\n",
    "# derive the error\n",
    "error = y - nn_output\n",
    "\n",
    "# error term (lower delta)\n",
    "error_term = error*sigmoid_prime(np.dot(x, w))\n",
    "\n",
    "# gradient descent step\n",
    "del_w = learn_rate*error_term*x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-16 Implement Gradient Descent\n",
    "1. First read the data and standardize it. (Data Cleanup)\n",
    "2. Initialize random weights and small learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "verbose = False\n",
    "max_row_disp = 5\n",
    "training_percent = 0.9\n",
    "random_seed = 42\n",
    "\n",
    "def read_csv():\n",
    "    admissions = pd.read_csv('assets/binaryL5-16.csv')\n",
    "    print(admissions.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    return admissions\n",
    "\n",
    "def modify_data():\n",
    "    # make dummy variables for rank\n",
    "    data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "    data = data.drop('rank', axis=1)\n",
    "    print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # Standarize the data for gre and gpa\n",
    "    for field in ['gre', 'gpa']:\n",
    "        mean, std = data[field].mean(), data[field].std()\n",
    "        data.loc[:,field] = (data[field]-mean)/std\n",
    "    \n",
    "    print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # Split off random x% of data for testing set.\n",
    "    np.random.seed(random_seed)\n",
    "    sample = np.random.choice(data.index, size=int(len(data)*training_percent), replace=False)\n",
    "    data, test_data = data.ix[sample], data.drop(sample)\n",
    "    \n",
    "    print(\"Training Data\") if verbose else print('')\n",
    "    print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    print(\"Testing Data\") if verbose else print('')\n",
    "    print(test_data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # spilt into Features and test\n",
    "    features, targets = data.drop('admit', axis=1), data['admit']\n",
    "    features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']\n",
    "    return features, targets, features_test, targets_test\n",
    "\n",
    "    \n",
    "admissions = read_csv()\n",
    "features, targets, features_test, targets_test = modify_data()\n",
    "\n",
    "print(features.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "print(targets.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "print(features_test.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "print(targets_test.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# use same random seed to make debugging easier\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "print('records: ', n_records, ', features: ', n_features) if verbose else print('')\n",
    "\n",
    "# Initialize random weights normailzed to 1/sqaure_root(number of features) to keep input small to sigmoid\n",
    "weights = np.random.normal(scale=1/n_features**.5, size=n_features)\n",
    "print('initial scaled weights: ', weights) if verbose else print('')\n",
    "\n",
    "# Neural Network hyper parameters\n",
    "epochs = 1000\n",
    "learn_rate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x,y in zip(features.values, targets):\n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "        error = y - output\n",
    "        error_term = error*output*(1-output)\n",
    "        del_w += learn_rate*error_term*x\n",
    "    weights += del_w\n",
    "    \n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L5-17 MultiLayer Perceptrons\n",
    "1. Calculate the input to the hidden layer.\n",
    "2. Calculate the hidden layer output.\n",
    "3. Calculate the input to the output layer.\n",
    "4. Calculate the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "verbose = False\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "n_input = 4\n",
    "n_hidden = 3\n",
    "n_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# make some fake data\n",
    "X = np.random.rand(4)\n",
    "print(X) if verbose else print('')\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(n_input, n_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(n_hidden, n_output))\n",
    "print(weights_input_to_hidden.T) if verbose else print('')\n",
    "print(weights_hidden_to_output) if verbose else print('')\n",
    "\n",
    "# calculate the output for the hidden layer\n",
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "# calculate the output for the total NN\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L5-18 Backpropagation Exercise\n",
    "1. Calculate the network error.\n",
    "2. Calculate the output layer error gradient.\n",
    "3. Use backpropagation to calculate the hidden layer error.\n",
    "4. Calculate the weight update steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "verbose = False\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6], [0.1, -0.2], [0.1, 0.7]])\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_in = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "print('Input for hidden layer: ', hidden_layer_in) if verbose else print('')\n",
    "print('Output from hidden layer: ', hidden_layer_out) if verbose else print('')\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "print('Input for output layer: ', output_layer_in) if verbose else print('')\n",
    "print('Final Output (y hat): ', output_layer_out) if verbose else print('')\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate error\n",
    "error = target - output_layer_out\n",
    "\n",
    "# TODO: Calculate error gradient for output layer\n",
    "del_err_output = error * output_layer_out * (1 - output_layer_out)\n",
    "\n",
    "# TODO: Calculate error gradient for hidden layer\n",
    "del_err_hidden = weights_hidden_output * del_err_output * hidden_layer_out * (1 - hidden_layer_out)\n",
    "# del_err_hidden = np.dot(weights_hidden_output, del_err_output) * hidden_layer_out * (1 - hidden_layer_out)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate*del_err_output*hidden_layer_out\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate*del_err_hidden*x[:,None]\n",
    "\n",
    "if verbose:\n",
    "    print('del_err_output: ', del_err_output)\n",
    "    print('del_err_hidden: ', del_err_hidden)\n",
    "    print('delta_w_h_o: ', delta_w_h_o)\n",
    "    print('delta_w_i_h: ', delta_w_i_h)\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L5-19 Implement Backpropagation on Admission Data\n",
    "1. Implement the forward pass.\n",
    "2. Implement the backpropagation algorithm.\n",
    "3. Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit  gre   gpa  rank\n",
      "    0  380  3.61     3\n",
      "    1  660  3.67     3\n",
      "...     ...   ...   ...\n",
      "    0  700  3.65     2\n",
      "    0  600  3.89     3\n",
      "records:  360 , features:  6\n",
      "Train loss:  0.230714881145\n",
      "Train loss:  0.228062559297\n",
      "Train loss:  0.22582441625\n",
      "Train loss:  0.223927926107\n",
      "Train loss:  0.222317753311\n",
      "Train loss:  0.220950968585\n",
      "Train loss:  0.219793619767\n",
      "Train loss:  0.218818286481\n",
      "Train loss:  0.21800234375\n",
      "Train loss:  0.217326733907\n",
      "Prediction accuracy: 0.650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "verbose = True\n",
    "max_row_disp = 5\n",
    "training_percent = 0.9\n",
    "random_seed = 21\n",
    "\n",
    "def read_csv():\n",
    "    admissions = pd.read_csv('assets/binaryL5-16.csv')\n",
    "    print(admissions.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    return admissions\n",
    "\n",
    "def modify_data():\n",
    "    # make dummy variables for rank\n",
    "    data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "    data = data.drop('rank', axis=1)\n",
    "#     print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # Standarize the data for gre and gpa\n",
    "    for field in ['gre', 'gpa']:\n",
    "        mean, std = data[field].mean(), data[field].std()\n",
    "        data.loc[:,field] = (data[field]-mean)/std\n",
    "    \n",
    "#     print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # Split off random x% of data for testing set.\n",
    "    np.random.seed(random_seed)\n",
    "    sample = np.random.choice(data.index, size=int(len(data)*training_percent), replace=False)\n",
    "    data, test_data = data.ix[sample], data.drop(sample)\n",
    "    \n",
    "#     print(\"Training Data\") if verbose else print('')\n",
    "#     print(data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "#     print(\"Testing Data\") if verbose else print('')\n",
    "#     print(test_data.to_string(index=False, max_rows=max_row_disp)) if verbose else print('')\n",
    "    \n",
    "    # spilt into Features and test\n",
    "    features, targets = data.drop('admit', axis=1), data['admit']\n",
    "    features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']\n",
    "    return features, targets, features_test, targets_test\n",
    "\n",
    "    \n",
    "admissions = read_csv()\n",
    "features, targets, features_test, targets_test = modify_data()\n",
    "\n",
    "if verbose:\n",
    "    pass\n",
    "#     print(features.to_string(index=False, max_rows=max_row_disp))\n",
    "#     print(targets.to_string(index=False, max_rows=max_row_disp))\n",
    "#     print(features_test.to_string(index=False, max_rows=max_row_disp))\n",
    "#     print(targets_test.to_string(index=False, max_rows=max_row_disp))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Hyper Parameters for the NN\n",
    "n_hidden = 2 # number of hidden layers\n",
    "epochs = 900\n",
    "learnrate = 0.05\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "print('records: ', n_records, ', features: ', n_features) if verbose else print('')\n",
    "\n",
    "# initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5, size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5, size=(n_hidden))\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_i_h = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_h_o = np.zeros(weights_hidden_output.shape)\n",
    "    for x,y in zip(features.values, targets):\n",
    "        # Forward pass\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output_input = np.dot(hidden_output, weights_hidden_output)\n",
    "        output = sigmoid(output_input)\n",
    "        \n",
    "        # Backward pass\n",
    "        error = y - output\n",
    "        del_err_output = error * output * (1 - output)\n",
    "        del_err_hidden = np.dot(weights_hidden_output, del_err_output) * hidden_output * (1 - hidden_output)\n",
    "        del_w_h_o += del_err_output * hidden_output\n",
    "        del_w_i_h += del_err_hidden * x[:,None]\n",
    "    weights_hidden_output += learnrate * del_w_h_o / n_records\n",
    "    weights_input_hidden += learnrate * del_w_i_h / n_records\n",
    "    \n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "        # Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
